"""
üõ°Ô∏è MODERADOR CON INTELIGENCIA ARTIFICIAL

Este es el 'CEREBRO' del bot moderador. Su trabajo es:

1. üì® Recibir mensajes del grupo de Telegram
2. ü§ñ Analizarlos con Google Gemini (IA)
3. üéØ Decidir qu√© acci√≥n tomar (aprobar, advertir, eliminar, etc.)
4. üìä Devolver el resultado con explicaci√≥n y nivel de confianza

COMPONENTES PRINCIPALES:
- ModerationAction: Las 5 acciones posibles (APPROVE, WARN, DELETE, BAN, TIMEOUT)
- ModerationResult: El resultado completo del an√°lisis
- ContentModerator: La clase principal que hace todo el trabajo
- analyze_message(): Funci√≥n simple para usar desde otros archivos

FLUJO DE TRABAJO:
mensaje ‚Üí Gemini API ‚Üí an√°lisis ‚Üí decisi√≥n ‚Üí acci√≥n
"""

import asyncio
import logging
from typing import Optional, Dict, Any, Union
from enum import Enum
from dataclasses import dataclass
from datetime import datetime

# LangChain imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate

# Configuraci√≥n local
from ...settings import settings

class ModerationAction(Enum):
    """
    üéØ LAS 5 ACCIONES POSIBLES DEL MODERADOR
    
    Estas son todas las decisiones que puede tomar la IA:
    
    APPROVE  = Mensaje est√° bien, no hacer nada
    WARN     = Enviar advertencia privada al usuario
    DELETE   = Eliminar el mensaje del grupo
    BAN      = Banear al usuario permanentemente
    TIMEOUT  = Silenciar al usuario por un tiempo
    
    La IA elige una de estas bas√°ndose en qu√© tan grave considera el mensaje.
    """
    APPROVE = "approve"      # ‚úÖ Mensaje aprobado - no hacer nada
    WARN = "warn"           # ‚ö†Ô∏è Advertencia al usuario - mensaje privado
    DELETE = "delete"       # üóëÔ∏è Eliminar mensaje - borrar del grupo
    BAN = "ban"             # üî® Banear usuario - expulsar permanentemente
    TIMEOUT = "timeout"     # ‚è∞ Timeout temporal - silenciar por X tiempo

@dataclass
class ModerationResult:
    """
    üìä RESULTADO COMPLETO DEL AN√ÅLISIS DE IA
    
    Esto es lo que devuelve la IA despu√©s de analizar un mensaje.
    Contiene toda la informaci√≥n necesaria para tomar una decisi√≥n.
    
    Campos:
    - action: Qu√© hacer (APPROVE, WARN, DELETE, BAN, TIMEOUT)
    - reason: Por qu√© la IA tom√≥ esa decisi√≥n (explicaci√≥n humana)
    - confidence: Qu√© tan segura est√° la IA (0.0 = insegura, 1.0 = muy segura)
    - message_analyzed: El mensaje original que se analiz√≥
    - timestamp: Cu√°ndo se hizo el an√°lisis
    - processing_time: Cu√°ntos segundos tard√≥ en analizarlo
    
    Ejemplo de uso:
    if result.action == ModerationAction.DELETE and result.confidence > 0.8:
        await message.delete()  # Solo eliminar si est√° muy segura
    """
    action: ModerationAction    # Qu√© acci√≥n tomar
    reason: str                 # Por qu√© se tom√≥ esa decisi√≥n
    confidence: float          # Nivel de confianza (0.0 a 1.0)
    message_analyzed: str      # El mensaje original
    timestamp: datetime        # Cu√°ndo se analiz√≥
    processing_time: float     # Segundos que tard√≥ 

# Configurar logging espec√≠fico para moderaci√≥n
logger = logging.getLogger(__name__)

# Configurar formato de logging m√°s detallado para moderaci√≥n
def setup_moderation_logging():
    """Configura logging espec√≠fico para moderaci√≥n"""
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - [MODERADOR] %(message)s'
    )
    
    # Handler para archivo de moderaci√≥n
    file_handler = logging.FileHandler('moderation.log')
    file_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    # Arreglar el problema del FieldInfo
    logger.setLevel(getattr(logging, str(settings.log_level).upper()))

# Inicializar logging
setup_moderation_logging()

class ContentModerator:
    """
    üß† CEREBRO PRINCIPAL DEL BOT MODERADOR
    
    Esta clase es el componente m√°s importante. Es quien hace todo el trabajo:
    
    RESPONSABILIDADES:
    1. üîå Conectarse con Google Gemini (IA)
    2. üìù Configurar las reglas de moderaci√≥n (prompt)
    3. üì® Recibir mensajes para analizar
    4. ü§ñ Enviar mensajes a la IA para an√°lisis
    5. üìä Procesar la respuesta de la IA
    6. ‚úÖ Devolver el resultado final
    
    M√âTODOS PRINCIPALES:
    - initialize(): Conecta con Gemini y configura el prompt
    - analyze_message(): Analiza un mensaje espec√≠fico (LA M√ÅS IMPORTANTE)
    
    FLUJO INTERNO:
    mensaje ‚Üí prompt + IA ‚Üí respuesta JSON ‚Üí ModerationResult
    """
    
    def __init__(self):
        """Inicializa el moderador con configuraci√≥n desde settings"""
        self.settings = settings
        self.llm: Optional[ChatGoogleGenerativeAI] = None
        self.prompt_template: Optional[ChatPromptTemplate] = None
        
        logger.info("üõ°Ô∏è Inicializando ContentModerator")
        logger.info(f"üìä Modelo: {self.settings.ai_model}")
        logger.info(f"üîß Moderaci√≥n habilitada: {self.settings.moderation_enabled}") 

    async def initialize(self) -> None:
        """
        Inicializa la conexi√≥n con Gemini y configura las chains.
        """
        try:
            logger.info("üîß Inicializando conexi√≥n con Gemini...")
            
            # Inicializar ChatGoogleGenerativeAI con LangChain
            self.llm = ChatGoogleGenerativeAI(
                model=self.settings.ai_model,
                google_api_key=self.settings.google_api_key,
                temperature=self.settings.ai_temperature,
                max_output_tokens=self.settings.ai_max_tokens,
                max_retries=3,  # Valor por defecto
                timeout=30      # Valor por defecto
            )
            
            # Configurar el prompt template para moderaci√≥n
            await self._setup_moderation_prompt()
            
            logger.info("‚úÖ Gemini inicializado correctamente")
            
        except Exception as e:
            logger.error(f"‚ùå Error al inicializar Gemini: {e}")
            raise 

    async def _setup_moderation_prompt(self) -> None:
        """
        üß† CONFIGURACI√ìN DEL PROMPT - EL ALMA DEL MODERADOR
        
        Esto es S√öPER IMPORTANTE de entender:
        
        El "prompt" es como las INSTRUCCIONES que le damos a la IA.
        Es como contratar a un moderador humano y explicarle:
        - Cu√°l es su trabajo
        - Qu√© reglas debe seguir  
        - C√≥mo debe responder
        
        Si cambias este prompt, cambias completamente el comportamiento del bot.
        """
        
        # üìã INSTRUCCIONES PARA LA IA (esto es lo que "lee" Gemini)
        system_prompt = """
        Eres un moderador experto para el grupo de Python CDMX en Telegram.
        Tu trabajo es mantener un ambiente sano y respetuoso, pero SIN ser restrictivo con conversaciones normales de una comunidad t√©cnica.
        
        üü¢ COMPLETAMENTE PERMITIDO (SIEMPRE APPROVE):
        - Preguntas t√©cnicas sobre Python, programaci√≥n, desarrollo
        - Discusiones sobre tecnolog√≠a, frameworks, herramientas
        - Compartir recursos, tutoriales, art√≠culos t√©cnicos
        - Ayuda con c√≥digo, debugging, errores
        - Ofertas de trabajo relacionadas con programaci√≥n
        - Conversaciones casuales entre miembros de la comunidad
        - Informaci√≥n sobre eventos, meetups, conferencias
        - Presentaciones personales ("Hola, soy nuevo")
        - Agradecimientos, felicitaciones, celebraciones
        - Memes y humor relacionado con programaci√≥n (incluso si mencionan otros lenguajes)
        - Discusiones sobre otros lenguajes de programaci√≥n (R, Java, etc.)
        - Preguntas sobre carrera profesional en tech
        - Compartir proyectos personales (sin spam excesivo)
        
        üî¥ PROHIBIDO (DELETE/WARN/BAN seg√∫n gravedad):
        - Insultos directos, ataques personales, lenguaje ofensivo
        - Contenido sexual expl√≠cito, pornograf√≠a
        - Drogas ilegales, armas, contenido violento
        - Pol√≠tica partidista, debates pol√≠ticos divisivos
        - Estafas, esquemas piramidales, MLM obvios
        - Spam comercial repetitivo (m√°s de 2 veces el mismo producto)
        - Links sospechosos, malware, phishing
        - Contenido racista, discriminatorio, hate speech
        - Promoci√≥n  de criptomonedas/trading 
        - Doxxing, informaci√≥n personal de otros sin permiso
        -Javascript
        -Hacking
        
        ‚ö†Ô∏è CRITERIO PARA ACCIONES:
        - APPROVE: 95% de los casos (s√© muy permisivo)
        - WARN: Solo para contenido borderline o primera ofensa menor
        - DELETE: Para spam claro, contenido inapropiado obvio
        - TIMEOUT: Para usuarios que insisten despu√©s de advertencia
        - BAN: Solo para casos extremos (spam masivo, contenido muy ofensivo)
        
        IMPORTANTE: 
        - S√â MUY PERMISIVO con conversaciones normales
        - Solo act√∫a contra contenido claramente problem√°tico
        - La comunidad debe sentirse libre de conversar
        - Responde SOLO con un JSON v√°lido:
        
        {{
            "action": "APPROVE|WARN|DELETE|BAN|TIMEOUT",
            "reason": "Explicaci√≥n breve y clara en espa√±ol",
            "confidence": 0.95
        }}
        """
        
        # üîó CREAR EL TEMPLATE DE CONVERSACI√ìN
        # Esto combina las instrucciones del sistema con el mensaje del usuario
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", system_prompt),  # Las instrucciones para la IA
            ("human", "Analiza este mensaje:\n\n{message}")  # El mensaje a analizar
        ]) 

    async def analyze_message(self, message: str, user_id: Optional[int] = None) -> ModerationResult:
        """
        üéØ FUNCI√ìN M√ÅS IMPORTANTE DEL BOT
        
        Esta funci√≥n hace TODO el trabajo de moderaci√≥n:
        
        PROCESO PASO A PASO:
        1. üì• Recibe el mensaje de texto
        2. ‚è±Ô∏è Inicia el cron√≥metro para medir velocidad
        3. üîç Verifica que todo est√© inicializado
        4. ü§ñ Crea la "chain" (prompt + IA) usando LangChain
        5. üì§ Env√≠a el mensaje a Gemini para an√°lisis
        6. üì• Recibe la respuesta JSON de Gemini
        7. üîß Parsea y valida la respuesta
        8. ‚úÖ Devuelve el resultado completo
        9. ‚ùå Si hay error, devuelve APPROVE por seguridad
        
        Args:
            message (str): El texto del mensaje a analizar
            user_id (Optional[int]): ID del usuario (para logs)
        
        Returns:
            ModerationResult: Decisi√≥n completa con acci√≥n, raz√≥n y confianza
            
        Ejemplo:
            result = await analyze_message("¬øC√≥mo instalar Django?")
            # result.action = APPROVE
            # result.reason = "Pregunta t√©cnica apropiada"
            # result.confidence = 0.95
        """
        start_time = asyncio.get_event_loop().time()
        
        try:
            logger.info(f"üîç Analizando mensaje de usuario {user_id}")
            logger.debug(f"üìù Mensaje: {message[:100]}...")
            
            # Verificar que el moderador est√© inicializado
            if not self.llm or not self.prompt_template:
                raise ValueError("Moderador no inicializado. Llama a initialize() primero.")
            
            # Crear la chain: prompt + LLM
            moderation_chain = self.prompt_template | self.llm
            
            # Ejecutar la chain
            logger.debug("ü§ñ Enviando mensaje a Gemini...")
            response = await moderation_chain.ainvoke({
                "message": message
            })
            
            logger.debug(f"üì® Respuesta de Gemini: {response.content}")
            
            # Parsear la respuesta JSON
            result = await self._parse_moderation_response(
                response.content, 
                message, 
                start_time
            )
            
            logger.info(f"‚úÖ An√°lisis completado: {result.action.value} ({result.confidence:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis: {e}")
            # Devolver resultado de error
            return ModerationResult(
                action=ModerationAction.APPROVE,  # En caso de error, aprobar
                reason=f"Error en an√°lisis: {str(e)}",
                confidence=0.0,
                message_analyzed=message,
                timestamp=datetime.now(),
                processing_time=asyncio.get_event_loop().time() - start_time
            )

    async def _parse_moderation_response(
        self, 
        response_content: str, 
        original_message: str, 
        start_time: float
    ) -> ModerationResult:
        """
        Parsea la respuesta JSON de Gemini y la convierte en ModerationResult.
        """
        import json
        
        try:
            # Limpiar la respuesta (a veces Gemini agrega texto extra)
            response_content = response_content.strip()
            
            # Buscar JSON en la respuesta
            start_idx = response_content.find('{')
            end_idx = response_content.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("No se encontr√≥ JSON v√°lido en la respuesta")
            
            json_str = response_content[start_idx:end_idx]
            parsed_response = json.loads(json_str)
            
            # Validar campos requeridos
            action_str = parsed_response.get('action', '').upper()
            reason = parsed_response.get('reason', 'Sin raz√≥n especificada')
            confidence = float(parsed_response.get('confidence', 0.5))
            
            # Convertir string a enum
            try:
                action = ModerationAction(action_str.lower())
            except ValueError:
                logger.warning(f"‚ö†Ô∏è Acci√≥n desconocida: {action_str}, usando APPROVE")
                action = ModerationAction.APPROVE
            
            # Crear resultado
            result = ModerationResult(
                action=action,
                reason=reason,
                confidence=min(max(confidence, 0.0), 1.0),  # Clamp entre 0 y 1
                message_analyzed=original_message,
                timestamp=datetime.now(),
                processing_time=asyncio.get_event_loop().time() - start_time
            )
            
            logger.debug(f"üìä Resultado parseado: {result}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error parseando respuesta: {e}")
            # Respuesta de fallback
            return ModerationResult(
                action=ModerationAction.APPROVE,
                reason=f"Error parseando respuesta: {str(e)}",
                confidence=0.0,
                message_analyzed=original_message,
                timestamp=datetime.now(),
                processing_time=asyncio.get_event_loop().time() - start_time
            ) 



# =============================================================================
# INSTANCIA GLOBAL Y FUNCI√ìN DE CONVENIENCIA
# =============================================================================

# Instancia global del moderador (patr√≥n singleton)
# Esto permite reutilizar la misma instancia en toda la aplicaci√≥n
# sin tener que inicializar m√∫ltiples veces la conexi√≥n con Gemini
moderator = ContentModerator()

async def analyze_message(message: str, user_id: Optional[int] = None) -> ModerationResult:
    """
    üéØ FUNCI√ìN PRINCIPAL PARA USAR DESDE OTROS M√ìDULOS
    
    Esta es la funci√≥n que llamar√°s desde telegram_client.py para moderar mensajes.
    
    Args:
        message (str): El texto del mensaje a analizar
        user_id (Optional[int]): ID del usuario que envi√≥ el mensaje (para logs)
    
    Returns:
        ModerationResult: Resultado completo del an√°lisis con:
            - action: APPROVE, WARN, DELETE, BAN, o TIMEOUT
            - reason: Explicaci√≥n de por qu√© se tom√≥ esa decisi√≥n
            - confidence: Nivel de confianza (0.0 a 1.0)
            - message_analyzed: El mensaje original
            - timestamp: Cu√°ndo se hizo el an√°lisis
            - processing_time: Cu√°nto tard√≥ en procesarse
    
    Ejemplo de uso:
        from .moderator.ai_analyzer import analyze_message
        
        result = await analyze_message("¬øC√≥mo instalar Django?", user_id=12345)
        
        if result.action == ModerationAction.DELETE:
            await message.delete()
        elif result.action == ModerationAction.WARN:
            await context.bot.send_message(chat_id=user_id, text="‚ö†Ô∏è Advertencia...")
    """
    # Si el moderador no est√° inicializado, lo inicializamos autom√°ticamente
    if not moderator.llm:
        logger.info("üîß Inicializando moderador autom√°ticamente...")
        await moderator.initialize()
    
    # Llamar al m√©todo de an√°lisis de la instancia global
    return await moderator.analyze_message(message, user_id) 